{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RIA_Novosti-EDA-n-grams-freq-1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgxzyrDI510YEBVI8De3ZC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekolonsky/RIA_news/blob/main/RIA_Novosti_EDA_n_grams_freq_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Frequency analysis with n-grams"
      ],
      "metadata": {
        "id": "d4Xq_xh18dAY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny5HGKR18JDK",
        "outputId": "8553a701-d83d-4dd8-b531-95049a0a25fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n"
          ]
        }
      ],
      "source": [
        "# install packages for NLP\n",
        "!pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, re\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "Oy7LAjNy8u45"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer(lang='ru')\n",
        "# пример - морфологический разбора слова \"идём\" \n",
        "print(morph.parse('идём'))\n",
        "normal = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFyf2ahn8vai",
        "outputId": "7fc26fd0-0956-412f-f94b-578b00bc41a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parse(word='идём', tag=OpencorporaTag('VERB,impf,intr plur,1per,pres,indc'), normal_form='идти', score=0.5, methods_stack=((DictionaryAnalyzer(), 'идём', 1696, 2),)), Parse(word='идём', tag=OpencorporaTag('VERB,impf,intr sing,impr,incl'), normal_form='идти', score=0.5, methods_stack=((DictionaryAnalyzer(), 'идём', 1696, 11),))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Функция для разбиений на токены\n",
        "\n",
        "separators = \";\", \",\", '\"', ':', '.','!', '?', ' ', '`', '%','$','*','(',')'\n",
        "regex_punctuation = '|'.join(map(re.escape, separators))\n",
        "url = 'https://raw.githubusercontent.com/ekolonsky/RIA_news/main/'\n",
        "\n",
        "\n",
        "def get_stopwords():\n",
        "    req = requests.get(url + 'stopwords.txt')\n",
        "    ans = req.text.split()\n",
        "    return ans\n",
        "stopwords = get_stopwords() # затем сделаем загрузку из словаря стоп-слов\n",
        "print(stopwords)\n",
        "\n",
        "def get_whitelist():\n",
        "    req = requests.get(url + 'whitelist.txt')\n",
        "    ans = req.text.split()\n",
        "    return ans\n",
        "whitelist = get_whitelist() # затем сделаем загрузку из словаря стоп-слов\n",
        "print(whitelist)\n",
        "\n",
        "\n",
        "\n",
        "def normalize(word):\n",
        "    word = word.lower()\n",
        "    if word not in normal:\n",
        "      normal[word] = morph.parse(word)[0].normal_form\n",
        "    return normal[word]\n",
        "\n",
        "def tokenize(text):\n",
        "    text = text.lower()\n",
        "    tokens = [normalize(word) for word in re.split(regex_punctuation,text)  \n",
        "      if not word.isnumeric()\n",
        "      and word != ''] \n",
        "    return [w for w in tokens if w not in stopwords] \n",
        "\n",
        "def generate_N_grams(tokens,ngram=1):\n",
        "    temp=zip(*[tokens[i:] for i in range(0,ngram)])\n",
        "    ans=[' '.join(ngram) for ngram in temp]\n",
        "    return ans\n",
        "\n",
        "# пример\n",
        "generate_N_grams(tokenize('В Москве назвали победителей Гран-при 15 Московского кинофестиваля \"Минотавр\".'),3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6RkVWKP9m2H",
        "outputId": "b0f7a093-a9e4-4204-b5e5-3ed0efbb2a40"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['а', 'ан', 'без', 'безусловно', 'благодаря', 'близ', 'будто', 'в', 'вблизи', 'ввиду', 'вглубь', 'вдоль', 'велено', 'верно', 'вероятно', 'включая', 'вместо', 'вне', 'внутри', 'возле', 'возможно', 'вокруг', 'вопреки', 'вправе', 'вслед', 'вследствие', 'вы', 'для', 'до', 'если', 'жаль', 'за', 'зато', 'значит', 'и', 'из', 'известно', 'из-за', 'из-по', 'из-под', 'или', 'исключая', 'к', 'как', 'когда', 'кое-кто', 'кое-что', 'коль', 'кроме', 'кто', 'кто-либо', 'кто-нибудь', 'кто-то', 'куда', 'ли', 'либо', 'между', 'многие', 'многое', 'можно', 'мы', 'на', 'над', 'надо', 'наконец-то', 'например', 'напротив', 'насчёт', 'негде', 'незачем', 'некого', 'некто', 'некуда', 'нельзя', 'немногие', 'немногое', 'необходимо', 'несмотря', 'нет', 'нету', 'нечего', 'нечто', 'ниже', 'никто', 'ничто', 'но', 'нужно', 'о', 'однако', 'около', 'он', 'она', 'они', 'оно', 'оное', 'от', 'относительно', 'перед', 'по', 'по-видимому', 'под', 'помимо', 'поскольку', 'после', 'посредством', 'пред', 'прежде', 'при', 'причём', 'про', 'против', 'прочее', 'путём', 'равно', 'ради', 'с', 'свыше', 'себя', 'сие', 'сквозь', 'скорее', 'согласно', 'спустя', 'среди', 'средь', 'тем', 'то', 'ты', 'у', 'хотя', 'чем', 'через', 'что', 'чтоб', 'чтобы', 'что-либо', 'что-нибудь', 'я', 'якобы']\n",
            "['заявить', 'рассказать', 'назвать', 'призвать', 'сообщить', 'предложить', 'оценить', 'прокомментировать', 'рассмотреть', 'объявить', 'подтвердить', 'предлагать', 'отказаться', 'просить', 'обсуждать', 'выразить', 'обещать', 'договориться', 'освещать', 'предупредить', 'опубликовать', 'сообщать', 'приговорить', 'приветствовать', 'раскритиковать', 'говорить', 'писать', 'пригласить', 'протестовать', 'прогнозировать', 'комментировать', 'поблагодарить', 'подтверждать', 'оценить', 'утверждать', 'предупреждать', 'настаивать', 'называть', 'отозвать', 'ратифицировать', 'напомнить']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['москва назвать победитель',\n",
              " 'назвать победитель гран-при',\n",
              " 'победитель гран-при московский',\n",
              " 'гран-при московский кинофестиваль',\n",
              " 'московский кинофестиваль минотавр']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# функция для извлечения даты новости из строки со ссылкой на новость\n",
        "def get_date(link):\n",
        "  pattern = r'\\/20[0-2][0-9][0-1][0-9][0-3][0-9]\\/'\n",
        "  result = re.search(pattern, link)\n",
        "\n",
        "  if result:\n",
        "    return result[0][1:-1]\n",
        "  else:\n",
        "    return ''\n",
        "  return \n",
        "\n",
        "# пример\n",
        "get_date('https://ria.ru/20041229/774359.html\tЖерар Депардье открыл в Париже второй ресторан')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A1fMl-IBEyQ9",
        "outputId": "eeda6c81-c572-442c-c894-8244f4eb6ec3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'20041229'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read and count n-grams"
      ],
      "metadata": {
        "id": "jWu8cKHFG1mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%time\n",
        "url = 'https://raw.githubusercontent.com/ekolonsky/RIA_news/main/'\n",
        "filenames = ['ria-{:02d}-1.txt'.format(i) for i in range(2,23)] \n",
        "filenames += ['ria-{:02d}-2.txt'.format(i) for i in range(2,22)]\n",
        "#filenames = ['ria-{:02d}-1.txt'.format(i) for i in range(2,3)]  # quick test\n",
        "\n",
        "ngrams_cnt = Counter()\n",
        "\n",
        "YEAR = '2014'\n",
        "\n",
        "for filename in filenames:\n",
        "  print(filename)\n",
        "  req = requests.get(url + filename)\n",
        "  for line in req.text.splitlines():\n",
        "    sep = line.find('\\t')\n",
        "    if sep == -1:\n",
        "      continue\n",
        "    link, news = line[:sep],line[sep+1:]\n",
        "    tokens = tokenize(news)\n",
        "    \n",
        "    in_whitelist =  any(word in whitelist for word in tokens)  # filter news by words in whitelist\n",
        "\n",
        "    date = get_date(link)\n",
        "    year = date[:4]\n",
        "    for n in [2, 3, 4]:\n",
        "      ngrams = generate_N_grams(tokens,n)\n",
        "      for ngram in ngrams:\n",
        "        ngrams_cnt[(ngram, n, year < YEAR, in_whitelist)] +=1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6P373E2G302",
        "outputId": "d9434132-af13-4e39-afe1-8236ab36efec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ria-02-1.txt\n",
            "ria-03-1.txt\n",
            "ria-04-1.txt\n",
            "ria-05-1.txt\n",
            "ria-06-1.txt\n",
            "ria-07-1.txt\n",
            "ria-08-1.txt\n",
            "ria-09-1.txt\n",
            "ria-10-1.txt\n",
            "ria-11-1.txt\n",
            "ria-12-1.txt\n",
            "ria-13-1.txt\n",
            "ria-14-1.txt\n",
            "ria-15-1.txt\n",
            "ria-16-1.txt\n",
            "ria-17-1.txt\n",
            "ria-18-1.txt\n",
            "ria-19-1.txt\n",
            "ria-20-1.txt\n",
            "ria-21-1.txt\n",
            "ria-22-1.txt\n",
            "ria-02-2.txt\n",
            "ria-03-2.txt\n",
            "ria-04-2.txt\n",
            "ria-05-2.txt\n",
            "ria-06-2.txt\n",
            "ria-07-2.txt\n",
            "ria-08-2.txt\n",
            "ria-09-2.txt\n",
            "ria-10-2.txt\n",
            "ria-11-2.txt\n",
            "ria-12-2.txt\n",
            "ria-13-2.txt\n",
            "ria-14-2.txt\n",
            "ria-15-2.txt\n",
            "ria-16-2.txt\n",
            "ria-17-2.txt\n",
            "ria-18-2.txt\n",
            "ria-19-2.txt\n",
            "ria-20-2.txt\n",
            "ria-21-2.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(ngrams_cnt), ngrams_cnt.most_common(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0unChALHzf1",
        "outputId": "50b0e2d8-35a9-4ae5-e9d1-5a394652a0bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27567934,\n",
              " [(('человек погибнуть', 2, True, False), 10614),\n",
              "  (('не быть', 2, True, False), 7495),\n",
              "  (('глава мид', 2, True, False), 6632),\n",
              "  (('федеральный округ', 2, True, False), 6486),\n",
              "  (('млн руб', 2, True, False), 6237),\n",
              "  (('человек погибнуть', 2, False, False), 6008),\n",
              "  (('принять участие', 2, True, False), 5957),\n",
              "  (('глава мид', 2, False, False), 5769),\n",
              "  (('теннисный турнир', 2, True, False), 5741),\n",
              "  (('сборная россия', 2, True, False), 5633),\n",
              "  (('мид рф', 2, True, False), 5310),\n",
              "  (('не быть', 2, False, False), 5295),\n",
              "  (('более тысяча', 2, False, False), 5002),\n",
              "  (('планировать освещать', 2, True, True), 4741),\n",
              "  (('событие который', 2, True, True), 4552),\n",
              "  (('владимир путин', 2, True, False), 4547),\n",
              "  (('мочь быть', 2, True, False), 4368),\n",
              "  (('риа новость', 2, True, False), 4285),\n",
              "  (('тысяча человек', 2, False, False), 4265),\n",
              "  (('млрд руб', 2, True, False), 4153)])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save"
      ],
      "metadata": {
        "id": "SlL_4_dAe6rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "\n",
        "with open('counter-100.txt','w') as file:\n",
        "    for key, value in ngrams_cnt.items():\n",
        "        if value > 100:\n",
        "          ngram = key[0]\n",
        "          n = key[1]\n",
        "          year = key[2]\n",
        "          wl = key[3]\n",
        "          file.write('{0};{1};{2};{3};{4}\\n'.format(ngram, n, year, wl, value))"
      ],
      "metadata": {
        "id": "udbO79gHH2Yv"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}